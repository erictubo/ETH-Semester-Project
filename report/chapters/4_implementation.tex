\chapter{Implementation}
\label{chapter:implementation}

This chapter gives an insight into the implementation of the proposed method, demonstrating the modularity and adaptability of the code. The pipeline is implemented in Python, with C++ integrated for optimization using Ceres Solver \cite{agarwal2022ceres}. \Cref{sec:python_classes} describes the Python code structure and classes, while \Cref{sec:c++_integration} outlines the integration of C++ code for optimization.

\section{Python Structure \& Classes}
\label{sec:python_classes}

The "main.py" file is the core of the pipeline where all other functions and classes are called. Here, one can interact with the code and adjust specific parameters. The sequence of calls is as follows:

\begin{enumerate}
    \item Define Camera objects with intrinsics and initial pose
    \item Create Railway object using frames along track
    \item Visualize Railway or frame data (GPS position, rotation, elevation)
    \item Visualize initial reprojections
    \item Create keyframes as list of Keyframe object
    \item Optimize pose of each camera across keyframes
    \item Compute stereo camera transformation \& accuracy w.r.t. calibration
\end{enumerate}

Data sources are specified in the "data.py" file. Along with the system paths where map and frame data is stored, known parameters such as the railway width and tram data \cite{strassmichael} are defined.


\subsection*{Camera}

Each camera is initialized as its own Camera object (file: "camera.py"), containing camera-specific data including intrinsics, pose (updated during optimization), as well as methods for reprojection and undistortion. Undistortion maps are automatically created and the camera model is updated accordingly. Other objects make use of the Camera object's methods for reprojection and undistortion.

\subsection*{Railway \& MapInfo}

The Railway object (file: "railway.py") is the output of processing the railway map and elevation data into relevant 3D point clouds. It uses a sequence of frames as input, whose GPS data are used to create a combined map. Additional inputs are the maximum interpolation gap between points ("max\_gap") and the search radius ahead / behind each frame that is used to find railway nodes ("r\_ahead", "r\_behind").

All outputs are automatically created at class initialization. Moreover, the Railway object is stored as a pickle file for later use with the same map, so that it does not need to be reprocessed each time.

The MapInfo class (file: "map\_info.py") contains methods to obtain non-railway map data, such as elevation and pole locations (currently unused). The elevation data is taken from \cite{geobasisbb2023dgm}.


\subsection*{Key(Frame), GPS \& Annotation}

The Keyframe object (file: "keyframe.py") contains all frame-specific data of the selected keyframes, including their ID, GPS data, images, associated cameras, and annotations. All information processing, such as obtaining the local 3D GPS points, is done automatically at initialization.

Frame is a simplified and more lightweight version of Keyframe that the latter it is based upon. It only contains ID and GPS data (without elevation) and is used for creation of the Railway object. The idea is to quickly create a dense sequence of frames to create the relevant Railway object, while only creating a sparse selection of the more sophisticated keyframes that take longer to initialize.

The GPS object (file: "gps.py") is part of each Frame/Keyframe and contains the processed GPS sensor pose readings. This includes the heading, different representations of the position and rotation, as well as local elevation computed via the MapInfo class.

The Annotation object is also part of each Keyframe (for each camera) and outsources the processing of the image annotations. It creates a 2D spline for each annotated pixel sequence read via a CSV file.

\subsection*{Transformation}

The Transformation class (file: "transformation.py") includes several static methods. These include operations on homogeneous transformation matrices, conversions between different rotation parametrizations, transformations of points between different coordinate frames, and spline interpolation. Computations from several other parts of the code are outsourced to this file.

\section{C++ Integration}
\label{sec:c++_integration}

Ceres solver has been selected for optimization due to its flexibility, efficiency, and documentation. However, the library is written in C++ and thus needs to be integrated into the existing Python pipeline. This is done using Pybind11 \cite{wenzel2023pybind11}, which creates Python bindings for C++ code. The following sections describe the optimization process and data transfer between Python and C++.

\subsection*{Optimization Process}

Optimization is done using Ceres Solver \cite{agarwal2022ceres}, for each camera separately and a specified number of iterations. At each iteration, a new Ceres problem is initialized, then for each keyframe a residual block is computed using the reprojection and correspondence search functions, the residual blocks are added to the problem using the cost function, and the problem is solved to update the camera pose.

% Reprojection function
\textbf{Reprojection function:} reprojects 3D GPS points to 2D image coordinates using the current camera pose and camera intrinsics. At first, the 3D GPS points are transformed to the camera frame using the current camera pose, and then reprojected to 2D image coordinates using the camera intrinsics.

% Correspondence search function
\textbf{Correspondence search function:} finds the closest reprojected point to each observed point. For each observed point, the closest reprojected point is determined by finding the smallest Euclidean distance between the observed point and the reprojected points. If there are now multiple correspondences for any reprojected point, only the closest observed point is kept as its correspondence. These one-to-one correspondences make sure that the problem is better conditioned and that the optimization converges faster.

% Cost function
\textbf{Cost function:} calculated as the sum of all residuals, which are the distance between corresponding reprojected and observed points. The Ceres cost functor keeps track of the residuals and their derivatives, which are used to update the camera pose. Minimizing the cost function is the goal of the optimization.

\subsection*{Python Bindings \& Data Transfer}

Data is passed between Python and C++ using Pybind11 \cite{wenzel2023pybind11} as a Git submodule. Pybind11 is a lightweight header-only library that exposes C++ types in Python and vice versa. It is used to create Python bindings for C++ code, which can then be called from Python. Other integration methods (e.g. PyCeres) have also been attempted but did not succeed or function as expected without errors.

Three functions are made available to Python that directly call their associated C++ functions: "add\_keyframe", "reset\_keyframes", and "update\_camera\_pose". The first two are used to create a new list of keyframes for a new camera, while the last one is used to optimize the pose of a camera over a fixed number of iterations.

To make relevant data available to C++, the "add\_keyframe" function is called, which creates a list of C++ Keyframe structs for the current camera. Inputs are the filename, camera ID, image, observed 2D points, and GPS 3D points. The first three inputs are for visualization purposes and storing the results with suitable filenames, while the last two are essential for the optimization. See \Cref{tab:keyframe_struct} for an overview of the types before and after conversion.

To optimize a new camera, the function "reset\_keyframes" is called, which resets the list of keyframes, after which the keyframe data of the new camera can be added again using the "add\_keyframe" function. The "reset\_keyframes" function takes no inputs.

Once the keyframe data has been added for a specific camera, the function "update\_camera\_pose" is called, which takes the camera pose, camera intrinsics, and number of iterations as inputs. The camera pose is a vector with 7 elements, containing the translation vector and quaternion in scalar-last representation ($x$, $y$, $z$, $q_x$, $q_y$, $q_z$ $q_w$). The camera intrinsics are a vector with 4 elements, containing the focal length and principal point coordinates ($f_x$, $f_y$, $c_x$, $c_y$). The number of iterations is an integer value. The output is the final camera pose, which is also a vector with 7 elements. An overview of the types is given in \Cref{tab:update_camera_pose}.

\begin{table}[h]
    \centering
    \caption{Keyframe struct attributes and their types.}
    \begin{tabular}{p{35mm} p{25mm} p{45mm}}
        \toprule
        \textbf{Variable} & \textbf{Python Type} & \textbf{Converted C++ Type} \\
        \midrule
        filename & str & std::string \\
        camera\_id & str & std::string \\
        image & np.ndarray & cv::Mat \\
        observed\_2D\_points & np.ndarray & std::vector\textless Eigen::Vector2d\textgreater \\
        gps\_3D\_points & np.ndarray & std::vector\textless Eigen::Vector3d\textgreater \\
        \bottomrule
    \end{tabular}
    \label{tab:keyframe_struct}
\end{table}

\begin{table}[h]
    \centering
    \caption{Pose update function inputs and their types.}
    \begin{tabular}{p{35mm} p{25mm} p{45mm}}
        \toprule
        \textbf{Variable} & \textbf{Python Type} & \textbf{Converted C++ Type} \\
        \midrule
        camera\_pose & np.ndarray & double[7] \\
        camera\_intrinsics & np.ndarray & double[4] \\
        iterations & int & int \\
        \bottomrule
    \end{tabular}
    \label{tab:update_camera_pose}
\end{table}