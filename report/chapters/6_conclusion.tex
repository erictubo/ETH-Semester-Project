\chapter{Conclusion}
\label{chapter:conclusion}

% Summary: method
This report has presented a complete extrinsic camera calibration and reprojection pipeline for a camera attached to a railway vehicle, given a set of images with associated GPS measurements as well as global map information. The 6 degree-of-freedom camera pose is estimated using an optimization formulation, where the railway map and elevation data are processed to reproject local railway tracks into camera view for each frame, upon which the error between reprojected and detected tracks in the image is minimized, utilizing an iterative closest points (ICP) algorithm.

% Summary: implementation
The proposed method has been implemented in a modular and adaptable pipeline. While the overall structure and interface of the code has been programmed in Python using an object-oriented approach, the optimization is performed in C++ using the Ceres Solver library. This allows for intuitive interaction with the code, but also provides the computational efficiency for the optimization algorithm.

% Evaluation: single frame convergence, robustness, stereo accuracy & precision, multi-frame accuracy, causes of error
Evaluation on a variety of scenes has shown that the method predictably converges within 10-50 ICP iterations, depending on scene complexity and initial pose estimate. Given a decent initial height and depth estimate, the method is robust to different track shapes and still manages to converge if the initial ICP correspondences are incorrect. More complex keyframes with depth-variability of the track actually improve the result and should be given preference as input for the optimization.
It has been demonstrated that the proposed method is able to both accurately and precisely estimate the camera pose, as compared to stereo camera calibration data. Especially the horizontal and vertical positions are very accurate, while the depth error is slightly larger yet without noticeable effect. Extending to multi-frame optimization, the accuracy of the method is limited by sensor noise, in particular the RTK-GPS rotation measurements, where small angular errors lead to reprojection inconsistencies. Beyond this limitation, everything is in place to perform consistent and accurate multi-frame optimization.

% Extensions: track detection, sensor fusion
An extension to this project to address the limitation of multi-frame optimization is sensor fusion of GPS measurements with IMU and odometry data. This would improve the accuracy of the state estimate and thus the reprojection error in multi-frame optimization. Another extension would be automated track detection using machine learning, which would allow the method to be applied to arbitrary scenes without manual annotation.

% Possible extensions to this project include track detection using machine learning as well as sensor fusion of the GPS measurements with IMU and odometry data. Automated track detection would allow the method to be applied to arbitrary scenes without manual annotation, while sensor fusion would improve the accuracy of the state estimate and thus the reprojection error in multi-frame optimization.